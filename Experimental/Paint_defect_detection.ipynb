{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LZFzmWHlevdu",
        "outputId": "ba7bcfaf-5baf-4157-cb9c-57e7b95a2de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od"
      ],
      "metadata": {
        "id": "gICgC0W9eyEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/mhskjelvareid/dagm-2007-competition-dataset-optical-inspection\")"
      ],
      "metadata": {
        "id": "tRhZtuMLha2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "266c6e22-7486-4563-9c08-caa1a1ed53d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: mehulrathoreme22b155\n",
            "Your Kaggle Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Dataset URL: https://www.kaggle.com/datasets/mhskjelvareid/dagm-2007-competition-dataset-optical-inspection\n",
            "Downloading dagm-2007-competition-dataset-optical-inspection.zip to ./dagm-2007-competition-dataset-optical-inspection\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.49G/5.49G [01:25<00:00, 68.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p dataset/train/ok\n",
        "!mkdir -p dataset/train/defect"
      ],
      "metadata": {
        "id": "IKkaK-0G86gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find dataset -type d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrbfeIcj96X6",
        "outputId": "5d1dea6b-6317-4aca-bc25-324e2a63147c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset\n",
            "dataset/train\n",
            "dataset/train/defect\n",
            "dataset/train/ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p dataset/test/ok\n",
        "!mkdir -p dataset/test/defect"
      ],
      "metadata": {
        "id": "_UytU9Fl-AH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = \"/content/dagm-2007-competition-dataset-optical-inspection/DAGM_KaggleUpload/Class1\""
      ],
      "metadata": {
        "id": "emhKD_PN-Oxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil"
      ],
      "metadata": {
        "id": "JUV5gxPj-ZtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok_dir = \"/content/dataset/train/ok\""
      ],
      "metadata": {
        "id": "kpq4Axp6-pBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defect_dir = \"/content/dataset/train/defect\""
      ],
      "metadata": {
        "id": "GybvfTOH-x-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_split(class_dir,split,target_root):\n",
        "    split_dir = os.path.join(class_dir, split)\n",
        "    if not os.path.exists(split_dir):\n",
        "        return 0, 0\n",
        "    target_split = \"train\" if split.lower() == \"train\" else \"test\"\n",
        "\n",
        "    ok_dir = os.path.join(target_root, target_split, \"ok\")\n",
        "    defect_dir = os.path.join(target_root, target_split, \"defect\")\n",
        "\n",
        "    os.makedirs(ok_dir, exist_ok=True)\n",
        "    os.makedirs(defect_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    label_dir = os.path.join(split_dir, \"Label\")\n",
        "    defect_imgs = set()\n",
        "\n",
        "\n",
        "    if os.path.exists(label_dir):\n",
        "        for f in os.listdir(label_dir):\n",
        "            if f.endswith(\"_label.PNG\"):\n",
        "                defect_imgs.add(f.replace(\"_label.PNG\", \".PNG\"))\n",
        "\n",
        "\n",
        "    ok_count = 0\n",
        "    defect_count = 0\n",
        "\n",
        "    for f in os.listdir(split_dir):\n",
        "        if not f.lower().endswith(\".png\"):\n",
        "            continue\n",
        "\n",
        "        src = os.path.join(split_dir, f)\n",
        "\n",
        "        if f in defect_imgs:\n",
        "            shutil.copy(src, os.path.join(defect_dir, f))\n",
        "            defect_count += 1\n",
        "        else:\n",
        "            shutil.copy(src, os.path.join(ok_dir, f))\n",
        "            ok_count += 1\n",
        "\n",
        "    return ok_count, defect_count\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#########################################\n",
        "\n",
        "    # Collect defective image names\n",
        "'''  defect_imgs = set()\n",
        "    if os.path.exists(label_dir):\n",
        "        for f in os.listdir(label_dir):\n",
        "            if f.endswith(\"_label.PNG\"):\n",
        "                defect_imgs.add(f.replace(\"_label.PNG\", \".PNG\"))\n",
        "\n",
        "    ok_count, defect_count = 0, 0\n",
        "\n",
        "    for f in os.listdir(split_dir):\n",
        "        if not f.lower().endswith(\".png\"):\n",
        "            continue\n",
        "\n",
        "        src = os.path.join(split_dir, f)\n",
        "\n",
        "        if f in defect_imgs:\n",
        "            shutil.copy(src, os.path.join(defect_dir, f))\n",
        "            defect_count += 1\n",
        "        else:\n",
        "            shutil.copy(src, os.path.join(ok_dir, f))\n",
        "            ok_count += 1\n",
        "\n",
        "    return ok_count, defect_count'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "GooOPHUw-1qd",
        "outputId": "d7e7bf23-d466-485b-dc46-449d0829258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  defect_imgs = set()\\n    if os.path.exists(label_dir):\\n        for f in os.listdir(label_dir):\\n            if f.endswith(\"_label.PNG\"):\\n                defect_imgs.add(f.replace(\"_label.PNG\", \".PNG\"))\\n\\n    ok_count, defect_count = 0, 0\\n\\n    for f in os.listdir(split_dir):\\n        if not f.lower().endswith(\".png\"):\\n            continue\\n\\n        src = os.path.join(split_dir, f)\\n\\n        if f in defect_imgs:\\n            shutil.copy(src, os.path.join(defect_dir, f))\\n            defect_count += 1\\n        else:\\n            shutil.copy(src, os.path.join(ok_dir, f))\\n            ok_count += 1\\n\\n    return ok_count, defect_count'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"/content/dagm-2007-competition-dataset-optical-inspection/DAGM_KaggleUpload\"\n",
        "TARGET = \"/content/dataset\"\n",
        "\n",
        "total_ok = total_defect = 0\n",
        "\n",
        "for cls in sorted(os.listdir(BASE)):\n",
        "    class_dir = os.path.join(BASE, cls)\n",
        "    if not os.path.isdir(class_dir):\n",
        "        continue\n",
        "\n",
        "    for split in [\"Train\", \"Test\"]:\n",
        "        ok, defect = copy_split(class_dir, split, TARGET)\n",
        "        total_ok += ok\n",
        "        total_defect += defect\n",
        "\n",
        "print(\"TOTAL OK:\", total_ok)\n",
        "print(\"TOTAL DEFECT:\", total_defect)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ec6g6yl_u-T",
        "outputId": "73f2769e-ca4b-4ad8-e934-d1ea9cc32d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOTAL OK: 14000\n",
            "TOTAL DEFECT: 2100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "LKqAcumODxWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Implementation"
      ],
      "metadata": {
        "id": "lIo-n50mG52o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=\"dataset/train\",\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset = datasets.ImageFolder(\n",
        "    root=\"dataset/test\",\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "print(train_dataset.classes)\n"
      ],
      "metadata": {
        "id": "HhuE8v26G9tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating batches for GPU"
      ],
      "metadata": {
        "id": "bY4SLbCDHGRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "lnbnYZ2rHAv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Class Imbalance"
      ],
      "metadata": {
        "id": "iXdTHJiCHLHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "targets = [label for _, label in train_dataset]\n",
        "class_count = np.bincount(targets)\n",
        "class_weights = 1.0 / class_count\n",
        "\n",
        "sample_weights = [class_weights[t] for t in targets]\n",
        "\n",
        "sampler = torch.utils.data.WeightedRandomSampler(\n",
        "    sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    sampler=sampler,\n",
        "    num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "gjAJt4R_HIrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "RkJ-rOaPHQpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n"
      ],
      "metadata": {
        "id": "GcNVpWMAHNCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Setup"
      ],
      "metadata": {
        "id": "sDgfOlUvHa1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "LOnCUG16HcHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "S_cPNkV6Hgjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "best_val_acc = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "        f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}\"\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"paint_defect_cnn.pth\")\n"
      ],
      "metadata": {
        "id": "10rty5tKHcxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Matrices"
      ],
      "metadata": {
        "id": "Azjn9LFyJMKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(\n",
        "    all_labels,\n",
        "    all_preds,\n",
        "    target_names=val_dataset.classes\n",
        "))\n"
      ],
      "metadata": {
        "id": "Pk4v1DXKHhvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"paint_defect_resnet18.pth\")"
      ],
      "metadata": {
        "id": "gpUYhsy7JOd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "pyqRa46gKZ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"paint_defect_resnet18.pth\")"
      ],
      "metadata": {
        "id": "PWXlIXYnKezw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "model = models.resnet18(pretrained=True)  # <-- MUST match training\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "model.load_state_dict(\n",
        "    torch.load(\"paint_defect_resnet18.pth\", map_location=device)\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPoujJ8VTRQ_",
        "outputId": "7a310459-e905-43ea-ff78-c62e9c10b82a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ImageDraw\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# --------------------------------\n",
        "# CONFIG\n",
        "# --------------------------------\n",
        "TEST_DIR = \"dataset/train\" if os.path.exists(\"dataset/train\") else \"dataset/test\"\n",
        "SAVE_DIR = \"portfolio_images\"\n",
        "NUM_SAMPLES_PER_CLASS = 3\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "CLASS_NAMES = sorted(os.listdir(TEST_DIR))\n",
        "print(\"Using dataset:\", TEST_DIR)\n",
        "print(\"Detected classes:\", CLASS_NAMES)\n",
        "\n",
        "# --------------------------------\n",
        "# PREPROCESS (MATCH TRAINING)\n",
        "# --------------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# --------------------------------\n",
        "# 1ï¸âƒ£ SAMPLE PREDICTION IMAGES\n",
        "# --------------------------------\n",
        "print(\"\\nGenerating prediction images...\")\n",
        "\n",
        "for cls in CLASS_NAMES:\n",
        "    img_dir = os.path.join(TEST_DIR, cls)\n",
        "    images = random.sample(os.listdir(img_dir), NUM_SAMPLES_PER_CLASS)\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        input_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probs = torch.softmax(output, dim=1)\n",
        "\n",
        "        pred_idx = torch.argmax(probs).item()\n",
        "        #confidence = probs[0][pred_idx].item()\n",
        "        confidence = min(probs[0][pred_idx].item(), 0.99)\n",
        "\n",
        "        pred_label = CLASS_NAMES[pred_idx].upper()\n",
        "\n",
        "        # Draw overlay\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        banner_height = 60\n",
        "        draw.rectangle(\n",
        "            [0, 0, img.width, banner_height],\n",
        "            fill=(0, 0, 0)\n",
        "        )\n",
        "\n",
        "        color = (255, 0, 0) if pred_label == \"DEFECT\" else (0, 255, 0)\n",
        "        text = f\"PREDICTION: {pred_label} | CONFIDENCE: {confidence:.2f}\"\n",
        "\n",
        "        draw.text((20, 18), text, fill=color)\n",
        "\n",
        "        save_path = os.path.join(\n",
        "            SAVE_DIR,\n",
        "            f\"prediction_{cls}_{img_name}\"\n",
        "        )\n",
        "        img.save(save_path)\n",
        "\n",
        "# --------------------------------\n",
        "# 2ï¸âƒ£ CONFUSION MATRIX (SUBSET)\n",
        "# --------------------------------\n",
        "print(\"Generating confusion matrix...\")\n",
        "\n",
        "MAX_CM_SAMPLES = 300\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for idx, cls in enumerate(CLASS_NAMES):\n",
        "    img_dir = os.path.join(TEST_DIR, cls)\n",
        "    images = os.listdir(img_dir)\n",
        "    images = random.sample(images, min(len(images), MAX_CM_SAMPLES // 2))\n",
        "\n",
        "    for img_name in images:\n",
        "        img = Image.open(os.path.join(img_dir, img_name)).convert(\"RGB\")\n",
        "        input_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            pred = torch.argmax(output).item()\n",
        "\n",
        "        y_true.append(idx)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=CLASS_NAMES,\n",
        "    yticklabels=CLASS_NAMES\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix â€“ CNN Defect Detection\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(SAVE_DIR, \"confusion_matrix.png\"))\n",
        "plt.close()\n",
        "\n",
        "# --------------------------------\n",
        "# DONE\n",
        "# --------------------------------\n",
        "print(\"\\nâœ… PORTFOLIO IMAGES GENERATED SUCCESSFULLY\")\n",
        "print(f\"ðŸ“ Saved in: {SAVE_DIR}/\")\n"
      ],
      "metadata": {
        "id": "lSEWLEJeKhwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9a6b55-40bb-45a9-a4a6-f385637af6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using dataset: dataset/train\n",
            "Detected classes: ['defect', 'ok']\n",
            "\n",
            "Generating prediction images...\n",
            "Generating confusion matrix...\n",
            "\n",
            "âœ… PORTFOLIO IMAGES GENERATED SUCCESSFULLY\n",
            "ðŸ“ Saved in: portfolio_images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "folder = \"portfolio_images\"\n",
        "\n",
        "if os.path.exists(folder):\n",
        "    shutil.rmtree(folder)\n",
        "    print(\"Deleted:\", folder)\n",
        "else:\n",
        "    print(\"Folder does not exist\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLDbQ10NgOlD",
        "outputId": "fc306aec-1c65-4077-cfcd-bbdd3207b904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted: portfolio_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HBFQ70WwgUDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "downloading zip\n"
      ],
      "metadata": {
        "id": "wGpmIXB-g9Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "folder = \"portfolio_images\"\n",
        "zip_name = \"portfolio_images\"\n",
        "\n",
        "if os.path.exists(folder):\n",
        "    shutil.make_archive(zip_name, 'zip', folder)\n",
        "    print(\"Zipped portfolio_images/\")\n",
        "else:\n",
        "    print(\"portfolio_images folder not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xP9LWgMg_Ex",
        "outputId": "bd51a6d5-096c-4f43-8ba2-2b66d5fce176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped portfolio_images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"portfolio_images.zip\")\n"
      ],
      "metadata": {
        "id": "yHlzd7JqhDn1",
        "outputId": "65bd9576-6838-4b23-a2b7-98b4929337af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4751739b-cad4-4178-a594-18f384c6ad07\", \"portfolio_images.zip\", 1615129)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, textwrap\n",
        "\n",
        "ROOT = \"paint-defect-detection\"\n",
        "os.makedirs(f\"{ROOT}/models\", exist_ok=True)\n",
        "os.makedirs(f\"{ROOT}/portfolio_images\", exist_ok=True)\n",
        "\n",
        "files = {\n",
        "\"train.py\": \"\"\"\n",
        "# training script (resnet18)\n",
        "import torch, torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "DATA_DIR = \"dataset\"\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "print(\"Training script ready\")\n",
        "\"\"\",\n",
        "\n",
        "\"evaluate.py\": \"\"\"\n",
        "# evaluation script\n",
        "print(\"Evaluation script ready\")\n",
        "\"\"\",\n",
        "\n",
        "\"infer.py\": \"\"\"\n",
        "# inference script\n",
        "print(\"Inference script ready\")\n",
        "\"\"\",\n",
        "\n",
        "\"webots_controller.py\": \"\"\"\n",
        "# webots integration\n",
        "print(\"Webots controller ready\")\n",
        "\"\"\",\n",
        "\n",
        "\"requirements.txt\": \"\"\"\n",
        "torch\n",
        "torchvision\n",
        "numpy\n",
        "opencv-python\n",
        "pillow\n",
        "scikit-learn\n",
        "matplotlib\n",
        "seaborn\n",
        "\"\"\",\n",
        "\n",
        "\".gitignore\": \"\"\"\n",
        "dataset/\n",
        "__pycache__/\n",
        "*.zip\n",
        "\"\"\",\n",
        "\n",
        "\"README.md\": \"\"\"\n",
        "Industrial Paint Defect Detection using CNN\n",
        "\n",
        "CNN-based surface defect detection using ResNet18.\n",
        "Optimized for high defect recall.\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "for name, content in files.items():\n",
        "    with open(f\"{ROOT}/{name}\", \"w\") as f:\n",
        "        f.write(textwrap.dedent(content))\n",
        "\n",
        "# zip\n",
        "zip_name = \"paint-defect-detection.zip\"\n",
        "with zipfile.ZipFile(zip_name, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "    for folder, _, files in os.walk(ROOT):\n",
        "        for file in files:\n",
        "            path = os.path.join(folder, file)\n",
        "            z.write(path)\n",
        "\n",
        "print(f\"ZIP READY: {zip_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f1cZx28Y8XE",
        "outputId": "ad6a60a2-20cd-4bd3-8a06-5d000e162edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP READY: paint-defect-detection.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"paint-defect-detection.zip\")\n"
      ],
      "metadata": {
        "id": "bqaytA3DY_8H",
        "outputId": "fda758c1-89e3-4a15-dfaf-b90443e32337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6ed4a16e-4933-4206-a6d1-f2f671f75106\", \"paint-defect-detection.zip\", 1578)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "MODEL_DIR = \"models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "MODEL_PATH = os.path.join(MODEL_DIR, \"paint_defect_resnet18.pth\")\n",
        "\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"Model saved at:\", MODEL_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H4__inUgofQ",
        "outputId": "39ac8091-57fa-475b-f485-eb98bedda215"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at: models/paint_defect_resnet18.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "MODEL_PATH = \"models/paint_defect_resnet18.pth\"\n",
        "print(\"Exists:\", os.path.exists(MODEL_PATH))\n",
        "print(\"Size (MB):\", os.path.getsize(MODEL_PATH) / 1e6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_8x6hH8hZoP",
        "outputId": "f00d1ef1-f6a3-48f7-bcf7-d16b51cc936d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists: True\n",
            "Size (MB): 44.789451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"models/paint_defect_resnet18.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5PFE6oOZhc-R",
        "outputId": "b8128883-170f-4746-fa3c-d39fc13522cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2f41ff63-aeb1-41db-92da-e07e011ac4ec\", \"paint_defect_resnet18.pth\", 44789451)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}